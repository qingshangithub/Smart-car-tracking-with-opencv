{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ggplot as plt\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from .mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data_frame = scipy.io.loadmat('F:\\MyDocuments\\Documents\\CourseraMaterial\\Machine Learning\\machine-learning-ex4\\ex4\\ex4data1.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creat image series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = data_frame['X']\n",
    "images = np.vsplit(img, 5000)\n",
    "image_series = pd.Series(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creat output labels (vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = data_frame['y']\n",
    "label_list = []\n",
    "for i in range(0, 5000):\n",
    "    newline = np.zeros(10, dtype='i')\n",
    "    label = int(labels[i])\n",
    "    if label == 10:\n",
    "        newline[0] = 1\n",
    "    else:\n",
    "        newline[label] = 1\n",
    "    label_list.append(newline)\n",
    "y_series = pd.Series(label_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combind to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'x': image_series, 'y': y_series}\n",
    "train_data = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = []\n",
    "for row in image_series:\n",
    "    xs.append(row.reshape(-1))\n",
    "x_mat = np.matrix(xs).T\n",
    "ys = []\n",
    "for row in y_series:\n",
    "    ys.append(row.reshape(-1))\n",
    "y_mat = np.matrix(ys).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    delta_init = 0.12\n",
    "\n",
    "    def __init__(self, num_i, num_o):\n",
    "        self.in_num = num_i\n",
    "        self.out_num = num_o\n",
    "        self.forward_matrix = np.matrix(np.random.uniform(-self.delta_init, self.delta_init, num_i * num_o)).reshape(\n",
    "            num_o, num_i)\n",
    "        self.bias = np.array(np.random.uniform(-self.delta_init, self.delta_init, num_o))\n",
    "\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, i, j, k, lam):\n",
    "        self.I_num = i\n",
    "        self.J_num = j\n",
    "        self.K_num = k\n",
    "        self.constrain_lambda = lam\n",
    "        self.layer_I = Layer(i, j)\n",
    "        self.layer_J = Layer(j, k)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def unpack(self, long_vector):\n",
    "        w_i_j = long_vector[0:(self.I_num*self.J_num)].reshape(self.J_num, self.I_num)\n",
    "        b_i = long_vector[(self.I_num*self.J_num): (self.I_num*self.J_num+self.J_num)]\n",
    "        w_j_k = long_vector[(self.I_num*self.J_num+self.J_num):\n",
    "            (self.I_num*self.J_num+self.J_num+self.J_num*self.K_num)].reshape(self.K_num, self.J_num)\n",
    "        b_j = long_vector[(self.I_num*self.J_num+self.J_num+self.J_num*self.K_num):len(long_vector)]\n",
    "        return w_i_j, b_i, w_j_k, b_j\n",
    "\n",
    "    def pack(self):\n",
    "        vector = np.hstack((\n",
    "            np.asarray(self.layer_I.forward_matrix).reshape(-1), self.layer_I.bias,\n",
    "            np.asarray(self.layer_J.forward_matrix).reshape(-1), self.layer_J.bias)\n",
    "        )\n",
    "        return vector\n",
    "\n",
    "    def predict(self, x_vec):\n",
    "        step_one = self.sigmoid(self.layer_I.forward_matrix * x_vec + self.layer_I.bias[:, np.newaxis])\n",
    "        step_two = self.sigmoid(self.layer_J.forward_matrix * step_one + self.layer_J.bias[:, np.newaxis])\n",
    "        return step_two\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(long_vec, x_vec, y_vec, self):\n",
    "        n = self.K_num\n",
    "        lamb = self.constrain_lambda\n",
    "        w_i_j, b_i, w_j_k, b_j = self.unpack(long_vec)\n",
    "        o_j = self.sigmoid(w_i_j * x_vec + b_i[:, np.newaxis])\n",
    "        o_k = self.sigmoid(w_j_k * o_j + b_j[:, np.newaxis])\n",
    "        return -1 / n * np.sum(np.multiply(y_vec,np.log(o_k)) + np.multiply((1 - y_vec), np.log(1 - o_k))) + \\\n",
    "               lamb / (2 * n) * (np.sum(np.multiply(w_i_j, w_i_j)) + np.sum(np.multiply(w_j_k, w_j_k)))\n",
    "\n",
    "    @staticmethod\n",
    "    def gradient(long_vec, x_vec, y_vec, self):\n",
    "        n = self.K_num\n",
    "        ncol = x_vec.shape[1]\n",
    "        lamd = self.constrain_lambda\n",
    "        w_i_j, b_i, w_j_k, b_j = self.unpack(long_vec)\n",
    "        o_i = x_vec\n",
    "        o_j = self.sigmoid(w_i_j * o_i + b_i[:, np.newaxis])\n",
    "        o_k = self.sigmoid(w_j_k * o_j + b_j[:, np.newaxis])\n",
    "        delta = -(1 / n) * (y_vec - o_k)\n",
    "        partial_w_j_k = delta * o_j.T + lamd / n * w_j_k\n",
    "        partial_b_j = delta * np.ones(ncol).reshape(ncol, 1)\n",
    "        delta = np.multiply(w_j_k.T * delta, np.multiply(o_j, (1 - o_j)))\n",
    "        partial_w_i_j = delta * o_i.T + lamd / n * w_i_j\n",
    "        partial_b_i = delta * np.ones(ncol).reshape(ncol, 1)\n",
    "        return np.hstack((\n",
    "            np.asarray(partial_w_i_j).reshape(-1), np.asarray(partial_b_i).reshape(-1),\n",
    "            np.asarray(partial_w_j_k).reshape(-1), np.asarray(partial_b_j).reshape(-1),)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def delta_gradient(long_vec,  x_vec, y_vec, self):\n",
    "        epsilon = 0.005\n",
    "        num = len(long_vec)\n",
    "        l = []\n",
    "        for i in range(0, num):\n",
    "            upper = np.array(long_vec, copy=True)\n",
    "            upper[i] += epsilon\n",
    "            lower = np.array(long_vec, copy=True)\n",
    "            lower[i] -= epsilon\n",
    "            delta = self.cost(upper, x_vec, y_vec, self) - self.cost(lower, x_vec, y_vec, self)\n",
    "            l.append(delta/(2*epsilon))\n",
    "        return np.array(l)\n",
    "\n",
    "    def gradient_check(self, x_vec, y_vec):\n",
    "        long_vec = self.pack()\n",
    "        delta_g = self.delta_gradient(long_vec, x_vec, y_vec, self)\n",
    "        bp_g = self.gradient(long_vec, x_vec, y_vec, self)\n",
    "        difference = bp_g - delta_g\n",
    "        return difference.max()\n",
    "\n",
    "    def bulk_train(self, x_series, y_series):\n",
    "        x_list = []\n",
    "        for row in x_series:\n",
    "            x_list.append(row.reshape(-1))\n",
    "        x_mat = np.matrix(x_list).T\n",
    "        y_list = []\n",
    "        for row in y_series:\n",
    "            y_list.append(row.reshape(-1))\n",
    "        y_mat = np.matrix(y_list).T\n",
    "        long_vector = self.pack()\n",
    "        result = minimize(fun=self.cost, x0=long_vector, method='L-BFGS-B', jac=self.gradient, args=(x_mat, y_mat, self))\n",
    "        self.layer_I.forward_matrix, self.layer_I.bias, \\\n",
    "            self.layer_J.forward_matrix, self.layer_J.bias = self.unpack(result.x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pratice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neuralnet = NeuralNetwork(400, 25, 10, 1.2)\n",
    "weights = neuralnet.pack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untrained performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.49919897],\n",
       "        [ 0.43737802],\n",
       "        [ 0.59397228],\n",
       "        [ 0.51320088],\n",
       "        [ 0.52831288],\n",
       "        [ 0.53096528],\n",
       "        [ 0.54167334],\n",
       "        [ 0.54244262],\n",
       "        [ 0.4988952 ],\n",
       "        [ 0.44866792]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_one = x_mat[:,1600]\n",
    "neuralnet.predict(image_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train in bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neuralnet.bulk_train(image_series, y_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  1.41538992e-03],\n",
       "        [  2.47289480e-03],\n",
       "        [  8.96794775e-05],\n",
       "        [  9.96590213e-01],\n",
       "        [  1.08247895e-05],\n",
       "        [  3.06320788e-03],\n",
       "        [  2.72898451e-04],\n",
       "        [  6.75370253e-04],\n",
       "        [  1.71933776e-03],\n",
       "        [  3.74895986e-03]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralnet.predict(image_one)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
